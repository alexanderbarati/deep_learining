{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classifying Fashion-MNIST\n",
    "\n",
    "Now it's your turn to build and train a neural network. You'll be using the [Fashion-MNIST dataset](https://github.com/zalandoresearch/fashion-mnist), a drop-in replacement for the MNIST dataset. MNIST is actually quite trivial with neural networks where you can easily achieve better than 97% accuracy. Fashion-MNIST is a set of 28x28 greyscale images of clothes. It's more complex than MNIST, so it's a better representation of the actual performance of your network, and a better representation of datasets you'll use in the real world.\n",
    "\n",
    "<img src='assets/fashion-mnist-sprite.png' width=500px>\n",
    "\n",
    "In this notebook, you'll build your own neural network. For the most part, you could just copy and paste the code from Part 3, but you wouldn't be learning. It's important for you to write the code yourself and get it to work. Feel free to consult the previous notebooks though as you work through this.\n",
    "\n",
    "First off, let's load the dataset through torchvision."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import helper\n",
    "from torchvision import datasets, transforms\n",
    "from torch import nn, optim\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a transform to normalize the data\n",
    "transform = transforms.Compose([transforms.ToTensor(),\n",
    "                                transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "# Download and load the training data\n",
    "trainset = datasets.FashionMNIST('~/.pytorch/F_MNIST_data/', download=True, train=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True)\n",
    "\n",
    "# Download and load the test data\n",
    "testset = datasets.FashionMNIST('~/.pytorch/F_MNIST_data/', download=True, train=False, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we can see one of the images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f56f0f6b358>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "image, label =  next(iter(trainloader))\n",
    "plt.imshow(image[0].view(28,28));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building the network\n",
    "\n",
    "Here you should define your network. As with MNIST, each image is 28x28 which is a total of 784 pixels, and there are 10 classes. You should include at least one hidden layer. We suggest you use ReLU activations for the layers and to return the logits or log-softmax from the forward pass. It's up to you how many layers you add and the size of those layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the network architecture \n",
    "\n",
    "class Calssifier(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(784, 256)\n",
    "        self.fc2 = nn.Linear(256, 128)\n",
    "        self.fc3 = nn.Linear(128, 64)\n",
    "        self.fc4 = nn.Linear(64, 10)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = x.view(x.shape[0], -1)\n",
    "        \n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.relu(self.fc3(x))\n",
    "        x = F.log_softmax(self.fc4(x), dim = 1)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train the network\n",
    "\n",
    "Now you should create your network and train it. First you'll want to define [the criterion](http://pytorch.org/docs/master/nn.html#loss-functions) (something like `nn.CrossEntropyLoss` or `nn.NLLLoss`) and [the optimizer](http://pytorch.org/docs/master/optim.html) (typically `optim.SGD` or `optim.Adam`).\n",
    "\n",
    "Then write the training code. Remember the training pass is a fairly straightforward process:\n",
    "\n",
    "* Make a forward pass through the network to get the logits \n",
    "* Use the logits to calculate the loss\n",
    "* Perform a backward pass through the network with `loss.backward()` to calculate the gradients\n",
    "* Take a step with the optimizer to update the weights\n",
    "\n",
    "By adjusting the hyperparameters (hidden units, learning rate, etc), you should be able to get the training loss below 0.4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Calssifier()\n",
    "criterion = nn.NLLLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr = 0.003)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Time to Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.5170152105692861\n",
      "Training loss: 0.39194393161136204\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-8a96cfbf4ac2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0me\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mrunning_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrainloader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m         \u001b[0mlog_ps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlog_ps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    262\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_workers\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# same-process loading\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    263\u001b[0m             \u001b[0mindices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample_iter\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 264\u001b[0;31m             \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollate_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    265\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    266\u001b[0m                 \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpin_memory_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    262\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_workers\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# same-process loading\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    263\u001b[0m             \u001b[0mindices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample_iter\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 264\u001b[0;31m             \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollate_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    265\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    266\u001b[0m                 \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpin_memory_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/torchvision-0.2.1-py3.6.egg/torchvision/datasets/mnist.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 77\u001b[0;31m             \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     78\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget_transform\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/torchvision-0.2.1-py3.6.egg/torchvision/transforms/transforms.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, img)\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransforms\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m             \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/torchvision-0.2.1-py3.6.egg/torchvision/transforms/transforms.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, tensor)\u001b[0m\n\u001b[1;32m    133\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 135\u001b[0;31m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    136\u001b[0m         \"\"\"\n\u001b[1;32m    137\u001b[0m         \u001b[0mArgs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# TODO: Train the network here\n",
    "epochs = 5\n",
    "\n",
    "for e in range(epochs):\n",
    "    running_loss = 0\n",
    "    for images, labels in trainloader:\n",
    "        log_ps = model(images)\n",
    "        loss = criterion(log_ps, labels)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "    else:\n",
    "        print(f\"Training loss: {running_loss/len(trainloader)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "let's test out model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataiter = iter(testloader)\n",
    "images, labels = dataiter.next()\n",
    "img = images[4]\n",
    "\n",
    "\n",
    "ps = torch .exp(model(img))\n",
    "\n",
    "helper.view_classify(img, ps, version = \"Fashion\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference and Validation\n",
    "\n",
    "Now that you have a trained network, you can use it for making predictions. This is typically called **inference**, a term borrowed from statistics. However, neural networks have a tendency to perform *too well* on the training data and aren't able to generalize to data that hasn't been seen before. This is called **overfitting** and it impairs inference performance. To test for overfitting while training, we measure the performance on data not in the training set called the **validation** set. We avoid overfitting through regularization such as dropout while monitoring the validation performance during training. In this notebook, I'll show you how to do this in PyTorch. \n",
    "\n",
    "As usual, let's start by loading the dataset through torchvision. You'll learn more about torchvision and loading data in a later part. This time we'll be taking advantage of the test set which you can get by setting `train=False` here:\n",
    "\n",
    "```python\n",
    "testset = datasets.FashionMNIST('~/.pytorch/F_MNIST_data/', download=True, train=False, transform=transform)\n",
    "```\n",
    "\n",
    "The test set contains images just like the training set. Typically you'll see 10-20% of the original dataset held out for testing and validation with the rest being used for training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "# Define a transform to normalize the data\n",
    "transform = transforms.Compose([transforms.ToTensor(),\n",
    "                                transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "# Download and load the training data\n",
    "trainset = datasets.FashionMNIST('~/.pytorch/F_MNIST_data/', download=True, train=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True)\n",
    "\n",
    "# Download and load the test data\n",
    "testset = datasets.FashionMNIST('~/.pytorch/F_MNIST_data/', download=True, train=False, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn, optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class Classifier(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(784, 256)\n",
    "        self.fc2 = nn.Linear(256, 128)\n",
    "        self.fc3 = nn.Linear(128, 64)\n",
    "        self.fc4 = nn.Linear(64, 10)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # make sure input tensor is flattened\n",
    "        x = x.view(x.shape[0], -1)\n",
    "        \n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.relu(self.fc3(x))\n",
    "        x = F.log_softmax(self.fc4(x), dim=1)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The goal of validation is to measure the model's performance on data that isn't part of the training set. Performance here is up to the developer to define though. Typically this is just accuracy, the percentage of classes the network predicted correctly. Other options are [precision and recall](https://en.wikipedia.org/wiki/Precision_and_recall#Definition_(classification_context)) and top-5 error rate. We'll focus on accuracy here. First I'll do a forward pass with one batch from the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 10])\n"
     ]
    }
   ],
   "source": [
    "model = Classifier()\n",
    "\n",
    "images, labels = next(iter(testloader))\n",
    "# Get the class probabilities\n",
    "ps = torch.exp(model(images))\n",
    "# Make sure the shape is appropriate, we should get 10 class probabilities for 64 examples\n",
    "print(ps.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the probabilities, we can get the most likely class using the `ps.topk` method. This returns the $k$ highest values. Since we just want the most likely class, we can use `ps.topk(1)`. This returns a tuple of the top-$k$ values and the top-$k$ indices. If the highest value is the fifth element, we'll get back 4 as the index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 3],\n",
      "        [ 3],\n",
      "        [ 3],\n",
      "        [ 9],\n",
      "        [ 3],\n",
      "        [ 9],\n",
      "        [ 3],\n",
      "        [ 9],\n",
      "        [ 3],\n",
      "        [ 3]])\n"
     ]
    }
   ],
   "source": [
    "top_p, top_class = ps.topk(1, dim=1)\n",
    "# Look at the most likely classes for the first 10 examples\n",
    "print(top_class[:10,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 1])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_class.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can check if the predicted classes match the labels. This is simple to do by equating `top_class` and `labels`, but we have to be careful of the shapes. Here `top_class` is a 2D tensor with shape `(64, 1)` while `labels` is 1D with shape `(64)`. To get the equality to work out the way we want, `top_class` and `labels` must have the same shape.\n",
    "\n",
    "If we do\n",
    "\n",
    "```python\n",
    "equals = top_class == labels\n",
    "```\n",
    "\n",
    "`equals` will have shape `(64, 64)`, try it yourself. What it's doing is comparing the one element in each row of `top_class` with each element in `labels` which returns 64 True/False boolean values for each row."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "equals = top_class == labels.view(*top_class.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 3],\n",
       "        [ 3],\n",
       "        [ 3],\n",
       "        [ 9],\n",
       "        [ 3],\n",
       "        [ 9],\n",
       "        [ 3],\n",
       "        [ 9],\n",
       "        [ 3],\n",
       "        [ 3],\n",
       "        [ 3],\n",
       "        [ 3],\n",
       "        [ 3],\n",
       "        [ 3],\n",
       "        [ 3],\n",
       "        [ 3],\n",
       "        [ 9],\n",
       "        [ 3],\n",
       "        [ 9],\n",
       "        [ 9],\n",
       "        [ 3],\n",
       "        [ 3],\n",
       "        [ 3],\n",
       "        [ 9],\n",
       "        [ 3],\n",
       "        [ 3],\n",
       "        [ 3],\n",
       "        [ 3],\n",
       "        [ 3],\n",
       "        [ 3],\n",
       "        [ 3],\n",
       "        [ 9],\n",
       "        [ 3],\n",
       "        [ 3],\n",
       "        [ 3],\n",
       "        [ 3],\n",
       "        [ 3],\n",
       "        [ 9],\n",
       "        [ 3],\n",
       "        [ 3],\n",
       "        [ 3],\n",
       "        [ 3],\n",
       "        [ 9],\n",
       "        [ 3],\n",
       "        [ 3],\n",
       "        [ 3],\n",
       "        [ 3],\n",
       "        [ 3],\n",
       "        [ 3],\n",
       "        [ 3],\n",
       "        [ 3],\n",
       "        [ 9],\n",
       "        [ 9],\n",
       "        [ 3],\n",
       "        [ 3],\n",
       "        [ 3],\n",
       "        [ 3],\n",
       "        [ 3],\n",
       "        [ 3],\n",
       "        [ 3],\n",
       "        [ 3],\n",
       "        [ 9],\n",
       "        [ 3],\n",
       "        [ 3]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we need to calculate the percentage of correct predictions. `equals` has binary values, either 0 or 1. This means that if we just sum up all the values and divide by the number of values, we get the percentage of correct predictions. This is the same operation as taking the mean, so we can get the accuracy with a call to `torch.mean`. If only it was that simple. If you try `torch.mean(equals)`, you'll get an error\n",
    "\n",
    "```\n",
    "RuntimeError: mean is not implemented for type torch.ByteTensor\n",
    "```\n",
    "\n",
    "This happens because `equals` has type `torch.ByteTensor` but `torch.mean` isn't implement for tensors with that type. So we'll need to convert `equals` to a float tensor. Note that when we take `torch.mean` it returns a scalar tensor, to get the actual value as a float we'll need to do `accuracy.item()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 17.1875%\n"
     ]
    }
   ],
   "source": [
    "accuracy = torch.mean(equals.type(torch.FloatTensor))\n",
    "print(f'Accuracy: {accuracy.item()*100}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The network is untrained so it's making random guesses and we should see an accuracy around 10%. Now let's train our network and include our validation pass so we can measure how well the network is performing on the test set. Since we're not updating our parameters in the validation pass, we can speed up the  by turning off gradients using `torch.no_grad()`:\n",
    "\n",
    "```python\n",
    "# turn off gradients\n",
    "with torch.no_grad():\n",
    "    # validation pass here\n",
    "    for images, labels in testloader:\n",
    "        ...\n",
    "```\n",
    "\n",
    ">**Implement the validation loop:**  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/30..  Training Loss: 0.512..  Test Loss: 0.458..  Test Accuracy: 0.835\n",
      "Epoch: 2/30..  Training Loss: 0.386..  Test Loss: 0.415..  Test Accuracy: 0.854\n",
      "Epoch: 3/30..  Training Loss: 0.357..  Test Loss: 0.393..  Test Accuracy: 0.858\n",
      "Epoch: 4/30..  Training Loss: 0.334..  Test Loss: 0.392..  Test Accuracy: 0.863\n",
      "Epoch: 5/30..  Training Loss: 0.312..  Test Loss: 0.377..  Test Accuracy: 0.868\n",
      "Epoch: 6/30..  Training Loss: 0.302..  Test Loss: 0.393..  Test Accuracy: 0.863\n",
      "Epoch: 7/30..  Training Loss: 0.290..  Test Loss: 0.377..  Test Accuracy: 0.872\n",
      "Epoch: 8/30..  Training Loss: 0.283..  Test Loss: 0.347..  Test Accuracy: 0.877\n",
      "Epoch: 9/30..  Training Loss: 0.272..  Test Loss: 0.375..  Test Accuracy: 0.872\n",
      "Epoch: 10/30..  Training Loss: 0.263..  Test Loss: 0.364..  Test Accuracy: 0.876\n",
      "Epoch: 11/30..  Training Loss: 0.262..  Test Loss: 0.384..  Test Accuracy: 0.876\n",
      "Epoch: 12/30..  Training Loss: 0.251..  Test Loss: 0.390..  Test Accuracy: 0.868\n",
      "Epoch: 13/30..  Training Loss: 0.249..  Test Loss: 0.377..  Test Accuracy: 0.882\n",
      "Epoch: 14/30..  Training Loss: 0.244..  Test Loss: 0.406..  Test Accuracy: 0.870\n",
      "Epoch: 15/30..  Training Loss: 0.235..  Test Loss: 0.390..  Test Accuracy: 0.882\n",
      "Epoch: 16/30..  Training Loss: 0.232..  Test Loss: 0.408..  Test Accuracy: 0.878\n",
      "Epoch: 17/30..  Training Loss: 0.230..  Test Loss: 0.392..  Test Accuracy: 0.871\n",
      "Epoch: 18/30..  Training Loss: 0.227..  Test Loss: 0.378..  Test Accuracy: 0.885\n",
      "Epoch: 19/30..  Training Loss: 0.222..  Test Loss: 0.379..  Test Accuracy: 0.881\n",
      "Epoch: 20/30..  Training Loss: 0.215..  Test Loss: 0.377..  Test Accuracy: 0.884\n",
      "Epoch: 21/30..  Training Loss: 0.211..  Test Loss: 0.441..  Test Accuracy: 0.870\n",
      "Epoch: 22/30..  Training Loss: 0.218..  Test Loss: 0.392..  Test Accuracy: 0.879\n",
      "Epoch: 23/30..  Training Loss: 0.213..  Test Loss: 0.394..  Test Accuracy: 0.881\n",
      "Epoch: 24/30..  Training Loss: 0.202..  Test Loss: 0.397..  Test Accuracy: 0.879\n",
      "Epoch: 25/30..  Training Loss: 0.196..  Test Loss: 0.392..  Test Accuracy: 0.885\n",
      "Epoch: 26/30..  Training Loss: 0.202..  Test Loss: 0.401..  Test Accuracy: 0.880\n",
      "Epoch: 27/30..  Training Loss: 0.191..  Test Loss: 0.403..  Test Accuracy: 0.881\n",
      "Epoch: 28/30..  Training Loss: 0.193..  Test Loss: 0.425..  Test Accuracy: 0.881\n",
      "Epoch: 29/30..  Training Loss: 0.193..  Test Loss: 0.424..  Test Accuracy: 0.883\n",
      "Epoch: 30/30..  Training Loss: 0.182..  Test Loss: 0.430..  Test Accuracy: 0.880\n"
     ]
    }
   ],
   "source": [
    "model = Classifier()\n",
    "criterion = nn.NLLLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.003)\n",
    "\n",
    "epochs = 30\n",
    "steps = 0\n",
    "\n",
    "train_losses, test_losses = [], []\n",
    "for e in range(epochs):\n",
    "    running_loss = 0\n",
    "    for images, labels in trainloader:\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        log_ps = model(images)\n",
    "        loss = criterion(log_ps, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "        \n",
    "    else:\n",
    "        test_loss = 0\n",
    "        accuracy = 0\n",
    "        \n",
    "        # Turn off gradients for validation, saves memory and computations\n",
    "        with torch.no_grad():\n",
    "            for images, labels in testloader:\n",
    "                log_ps = model(images)\n",
    "                test_loss += criterion(log_ps, labels)\n",
    "                \n",
    "                ps = torch.exp(log_ps)\n",
    "                top_p, top_class = ps.topk(1, dim=1)\n",
    "                equals = top_class == labels.view(*top_class.shape)\n",
    "                accuracy += torch.mean(equals.type(torch.FloatTensor))\n",
    "                \n",
    "        train_losses.append(running_loss/len(trainloader))\n",
    "        test_losses.append(test_loss/len(testloader))\n",
    "\n",
    "        print(\"Epoch: {}/{}.. \".format(e+1, epochs),\n",
    "              \"Training Loss: {:.3f}.. \".format(running_loss/len(trainloader)),\n",
    "              \"Test Loss: {:.3f}.. \".format(test_loss/len(testloader)),\n",
    "              \"Test Accuracy: {:.3f}\".format(accuracy/len(testloader)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7f56e80c8e80>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f56e82a6710>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(train_losses, label='Training loss')\n",
    "plt.plot(test_losses, label='Validation loss')\n",
    "plt.legend(frameon=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overfitting\n",
    "\n",
    "If we look at the training and validation losses as we train the network, we can see a phenomenon known as overfitting.\n",
    "\n",
    "<img src='assets/overfitting.png' width=450px>\n",
    "\n",
    "The network learns the training set better and better, resulting in lower training losses. However, it starts having problems generalizing to data outside the training set leading to the validation loss increasing. The ultimate goal of any deep learning model is to make predictions on new data, so we should strive to get the lowest validation loss possible. One option is to use the version of the model with the lowest validation loss, here the one around 8-10 training epochs. This strategy is called *early-stopping*. In practice, you'd save the model frequently as you're training then later choose the model with the lowest validation loss.\n",
    "\n",
    "The most common method to reduce overfitting (outside of early-stopping) is *dropout*, where we randomly drop input units. This forces the network to share information between weights, increasing it's ability to generalize to new data. Adding dropout in PyTorch is straightforward using the [`nn.Dropout`](https://pytorch.org/docs/stable/nn.html#torch.nn.Dropout) module.\n",
    "\n",
    "```python\n",
    "class Classifier(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(784, 256)\n",
    "        self.fc2 = nn.Linear(256, 128)\n",
    "        self.fc3 = nn.Linear(128, 64)\n",
    "        self.fc4 = nn.Linear(64, 10)\n",
    "        \n",
    "        # Dropout module with 0.2 drop probability\n",
    "        self.dropout = nn.Dropout(p=0.2)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # make sure input tensor is flattened\n",
    "        x = x.view(x.shape[0], -1)\n",
    "        \n",
    "        # Now with dropout\n",
    "        x = self.dropout(F.relu(self.fc1(x)))\n",
    "        x = self.dropout(F.relu(self.fc2(x)))\n",
    "        x = self.dropout(F.relu(self.fc3(x)))\n",
    "        \n",
    "        # output so no dropout here\n",
    "        x = F.log_softmax(self.fc4(x), dim=1)\n",
    "        \n",
    "        return x\n",
    "```\n",
    "\n",
    "During training we want to use dropout to prevent overfitting, but during inference we want to use the entire network. So, we need to turn off dropout during validation, testing, and whenever we're using the network to make predictions. To do this, you use `model.eval()`. This sets the model to evaluation mode where the dropout probability is 0. You can turn dropout back on by setting the model to train mode with `model.train()`. In general, the pattern for the validation loop will look like this, where you turn off gradients, set the model to evaluation mode, calculate the validation loss and metric, then set the model back to train mode.\n",
    "\n",
    "```python\n",
    "# turn off gradients\n",
    "with torch.no_grad():\n",
    "    \n",
    "    # set model to evaluation mode\n",
    "    model.eval()\n",
    "    \n",
    "    # validation pass here\n",
    "    for images, labels in testloader:\n",
    "        ...\n",
    "\n",
    "# set model back to train mode\n",
    "model.train()\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Classifier(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(784, 256)\n",
    "        self.fc2 = nn.Linear(256, 128)\n",
    "        self.fc3 = nn.Linear(128, 64)\n",
    "        self.fc4 = nn.Linear(64, 10)\n",
    "\n",
    "        # Dropout module with 0.2 drop probability\n",
    "        self.dropout = nn.Dropout(p=0.2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # make sure input tensor is flattened\n",
    "        x = x.view(x.shape[0], -1)\n",
    "\n",
    "        # Now with dropout\n",
    "        x = self.dropout(F.relu(self.fc1(x)))\n",
    "        x = self.dropout(F.relu(self.fc2(x)))\n",
    "        x = self.dropout(F.relu(self.fc3(x)))\n",
    "\n",
    "        # output so no dropout here\n",
    "        x = F.log_softmax(self.fc4(x), dim=1)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/30..  Training Loss: 0.601..  Test Loss: 0.463..  Test Accuracy: 0.830\n",
      "Epoch: 2/30..  Training Loss: 0.481..  Test Loss: 0.446..  Test Accuracy: 0.839\n",
      "Epoch: 3/30..  Training Loss: 0.450..  Test Loss: 0.403..  Test Accuracy: 0.855\n",
      "Epoch: 4/30..  Training Loss: 0.431..  Test Loss: 0.423..  Test Accuracy: 0.854\n",
      "Epoch: 5/30..  Training Loss: 0.416..  Test Loss: 0.420..  Test Accuracy: 0.849\n",
      "Epoch: 6/30..  Training Loss: 0.414..  Test Loss: 0.406..  Test Accuracy: 0.861\n",
      "Epoch: 7/30..  Training Loss: 0.405..  Test Loss: 0.403..  Test Accuracy: 0.854\n",
      "Epoch: 8/30..  Training Loss: 0.395..  Test Loss: 0.401..  Test Accuracy: 0.860\n",
      "Epoch: 9/30..  Training Loss: 0.394..  Test Loss: 0.381..  Test Accuracy: 0.861\n",
      "Epoch: 10/30..  Training Loss: 0.387..  Test Loss: 0.379..  Test Accuracy: 0.867\n",
      "Epoch: 11/30..  Training Loss: 0.387..  Test Loss: 0.407..  Test Accuracy: 0.855\n",
      "Epoch: 12/30..  Training Loss: 0.379..  Test Loss: 0.386..  Test Accuracy: 0.868\n",
      "Epoch: 13/30..  Training Loss: 0.376..  Test Loss: 0.376..  Test Accuracy: 0.872\n",
      "Epoch: 14/30..  Training Loss: 0.375..  Test Loss: 0.393..  Test Accuracy: 0.864\n",
      "Epoch: 15/30..  Training Loss: 0.369..  Test Loss: 0.387..  Test Accuracy: 0.869\n",
      "Epoch: 16/30..  Training Loss: 0.363..  Test Loss: 0.393..  Test Accuracy: 0.865\n",
      "Epoch: 17/30..  Training Loss: 0.374..  Test Loss: 0.388..  Test Accuracy: 0.866\n",
      "Epoch: 18/30..  Training Loss: 0.364..  Test Loss: 0.397..  Test Accuracy: 0.865\n",
      "Epoch: 19/30..  Training Loss: 0.366..  Test Loss: 0.399..  Test Accuracy: 0.865\n",
      "Epoch: 20/30..  Training Loss: 0.356..  Test Loss: 0.375..  Test Accuracy: 0.872\n",
      "Epoch: 21/30..  Training Loss: 0.359..  Test Loss: 0.386..  Test Accuracy: 0.869\n",
      "Epoch: 22/30..  Training Loss: 0.355..  Test Loss: 0.383..  Test Accuracy: 0.871\n",
      "Epoch: 23/30..  Training Loss: 0.352..  Test Loss: 0.387..  Test Accuracy: 0.873\n",
      "Epoch: 24/30..  Training Loss: 0.353..  Test Loss: 0.376..  Test Accuracy: 0.875\n",
      "Epoch: 25/30..  Training Loss: 0.347..  Test Loss: 0.380..  Test Accuracy: 0.872\n",
      "Epoch: 26/30..  Training Loss: 0.343..  Test Loss: 0.385..  Test Accuracy: 0.875\n",
      "Epoch: 27/30..  Training Loss: 0.348..  Test Loss: 0.406..  Test Accuracy: 0.867\n",
      "Epoch: 28/30..  Training Loss: 0.352..  Test Loss: 0.380..  Test Accuracy: 0.870\n",
      "Epoch: 29/30..  Training Loss: 0.338..  Test Loss: 0.381..  Test Accuracy: 0.876\n",
      "Epoch: 30/30..  Training Loss: 0.343..  Test Loss: 0.392..  Test Accuracy: 0.869\n"
     ]
    }
   ],
   "source": [
    "model = Classifier()\n",
    "criterion = nn.NLLLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.003)\n",
    "\n",
    "epochs = 30\n",
    "steps = 0\n",
    "\n",
    "train_losses, test_losses = [], []\n",
    "for e in range(epochs):\n",
    "    running_loss = 0\n",
    "    for images, labels in trainloader:\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        log_ps = model(images)\n",
    "        loss = criterion(log_ps, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "        \n",
    "    else:\n",
    "        test_loss = 0\n",
    "        accuracy = 0\n",
    "        \n",
    "        # Turn off gradients for validation, saves memory and computations\n",
    "        with torch.no_grad():\n",
    "            model.eval()\n",
    "            for images, labels in testloader:\n",
    "                log_ps = model(images)\n",
    "                test_loss += criterion(log_ps, labels)\n",
    "                \n",
    "                ps = torch.exp(log_ps)\n",
    "                top_p, top_class = ps.topk(1, dim=1)\n",
    "                equals = top_class == labels.view(*top_class.shape)\n",
    "                accuracy += torch.mean(equals.type(torch.FloatTensor))\n",
    "        \n",
    "        model.train()\n",
    "        \n",
    "        train_losses.append(running_loss/len(trainloader))\n",
    "        test_losses.append(test_loss/len(testloader))\n",
    "\n",
    "        print(\"Epoch: {}/{}.. \".format(e+1, epochs),\n",
    "              \"Training Loss: {:.3f}.. \".format(running_loss/len(trainloader)),\n",
    "              \"Test Loss: {:.3f}.. \".format(test_loss/len(testloader)),\n",
    "              \"Test Accuracy: {:.3f}\".format(accuracy/len(testloader)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7f56e8029898>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f56e82a66d8>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(train_losses, label='Training loss')\n",
    "plt.plot(test_losses, label='Validation loss')\n",
    "plt.legend(frameon=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference\n",
    "\n",
    "Now that the model is trained, we can use it for inference. We've done this before, but now we need to remember to set the model in inference mode with `model.eval()`. You'll also want to turn off autograd with the `torch.no_grad()` context."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f56e803b630>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Import helper module (should be in the repo)\n",
    "import helper\n",
    "\n",
    "# Test out your network!\n",
    "\n",
    "model.eval()\n",
    "\n",
    "dataiter = iter(testloader)\n",
    "images, labels = dataiter.next()\n",
    "img = images[0]\n",
    "# Convert 2D image to 1D vector\n",
    "img = img.view(1, 784)\n",
    "\n",
    "# Calculate the class probabilities (softmax) for img\n",
    "with torch.no_grad():\n",
    "    output = model.forward(img)\n",
    "\n",
    "ps = torch.exp(output)\n",
    "\n",
    "# Plot the image and probabilities\n",
    "helper.view_classify(img.view(1, 28, 28), ps, version='Fashion')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving and Loading Models\n",
    "\n",
    "In this notebook, I'll show you how to save and load models with PyTorch. This is important because you'll often want to load previously trained models to use in making predictions or to continue training on new data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fc_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz\n",
      "Processing...\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "# Define a transform to normalize the data\n",
    "transform = transforms.Compose([transforms.ToTensor(),\n",
    "                                transforms.Normalize((0.5,), (0.5,))])\n",
    "# Download and load the training data\n",
    "trainset = datasets.FashionMNIST('F_MNIST_data/', download=True, train=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True)\n",
    "\n",
    "# Download and load the test data\n",
    "testset = datasets.FashionMNIST('F_MNIST_data/', download=True, train=False, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f56e8086d68>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "image, label = next(iter(trainloader))\n",
    "helper.imshow(image[0,:]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train a network\n",
    "\n",
    "To make things more concise here, I moved the model architecture and training code from the last part to a file called `fc_model`. Importing this, we can easily create a fully-connected network with `fc_model.Network`, and train the network using `fc_model.train`. I'll use this model (once it's trained) to demonstrate how we can save and load models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the network, define the criterion and optimizer\n",
    "\n",
    "model = fc_model.Network(784, 10, [512, 256, 128])\n",
    "criterion = nn.NLLLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/2..  Training Loss: 1.735..  Test Loss: 0.941..  Test Accuracy: 0.656\n",
      "Epoch: 1/2..  Training Loss: 1.025..  Test Loss: 0.774..  Test Accuracy: 0.689\n",
      "Epoch: 1/2..  Training Loss: 0.854..  Test Loss: 0.696..  Test Accuracy: 0.733\n",
      "Epoch: 1/2..  Training Loss: 0.794..  Test Loss: 0.652..  Test Accuracy: 0.751\n",
      "Epoch: 1/2..  Training Loss: 0.748..  Test Loss: 0.632..  Test Accuracy: 0.758\n",
      "Epoch: 1/2..  Training Loss: 0.718..  Test Loss: 0.618..  Test Accuracy: 0.765\n",
      "Epoch: 1/2..  Training Loss: 0.718..  Test Loss: 0.571..  Test Accuracy: 0.780\n",
      "Epoch: 1/2..  Training Loss: 0.612..  Test Loss: 0.576..  Test Accuracy: 0.779\n",
      "Epoch: 1/2..  Training Loss: 0.682..  Test Loss: 0.563..  Test Accuracy: 0.781\n",
      "Epoch: 1/2..  Training Loss: 0.670..  Test Loss: 0.551..  Test Accuracy: 0.800\n",
      "Epoch: 1/2..  Training Loss: 0.651..  Test Loss: 0.542..  Test Accuracy: 0.801\n",
      "Epoch: 1/2..  Training Loss: 0.646..  Test Loss: 0.562..  Test Accuracy: 0.796\n",
      "Epoch: 1/2..  Training Loss: 0.617..  Test Loss: 0.540..  Test Accuracy: 0.803\n",
      "Epoch: 1/2..  Training Loss: 0.624..  Test Loss: 0.521..  Test Accuracy: 0.808\n",
      "Epoch: 1/2..  Training Loss: 0.590..  Test Loss: 0.514..  Test Accuracy: 0.806\n",
      "Epoch: 1/2..  Training Loss: 0.603..  Test Loss: 0.501..  Test Accuracy: 0.821\n",
      "Epoch: 1/2..  Training Loss: 0.575..  Test Loss: 0.508..  Test Accuracy: 0.817\n",
      "Epoch: 1/2..  Training Loss: 0.598..  Test Loss: 0.506..  Test Accuracy: 0.812\n",
      "Epoch: 1/2..  Training Loss: 0.570..  Test Loss: 0.486..  Test Accuracy: 0.820\n",
      "Epoch: 1/2..  Training Loss: 0.589..  Test Loss: 0.539..  Test Accuracy: 0.807\n",
      "Epoch: 1/2..  Training Loss: 0.591..  Test Loss: 0.489..  Test Accuracy: 0.816\n",
      "Epoch: 1/2..  Training Loss: 0.564..  Test Loss: 0.486..  Test Accuracy: 0.819\n",
      "Epoch: 1/2..  Training Loss: 0.572..  Test Loss: 0.513..  Test Accuracy: 0.803\n",
      "Epoch: 2/2..  Training Loss: 0.565..  Test Loss: 0.494..  Test Accuracy: 0.811\n",
      "Epoch: 2/2..  Training Loss: 0.555..  Test Loss: 0.478..  Test Accuracy: 0.828\n",
      "Epoch: 2/2..  Training Loss: 0.581..  Test Loss: 0.481..  Test Accuracy: 0.824\n",
      "Epoch: 2/2..  Training Loss: 0.565..  Test Loss: 0.473..  Test Accuracy: 0.824\n",
      "Epoch: 2/2..  Training Loss: 0.565..  Test Loss: 0.489..  Test Accuracy: 0.823\n",
      "Epoch: 2/2..  Training Loss: 0.538..  Test Loss: 0.469..  Test Accuracy: 0.827\n",
      "Epoch: 2/2..  Training Loss: 0.533..  Test Loss: 0.467..  Test Accuracy: 0.833\n",
      "Epoch: 2/2..  Training Loss: 0.530..  Test Loss: 0.475..  Test Accuracy: 0.826\n",
      "Epoch: 2/2..  Training Loss: 0.525..  Test Loss: 0.467..  Test Accuracy: 0.826\n",
      "Epoch: 2/2..  Training Loss: 0.545..  Test Loss: 0.453..  Test Accuracy: 0.835\n",
      "Epoch: 2/2..  Training Loss: 0.562..  Test Loss: 0.456..  Test Accuracy: 0.838\n",
      "Epoch: 2/2..  Training Loss: 0.566..  Test Loss: 0.464..  Test Accuracy: 0.833\n",
      "Epoch: 2/2..  Training Loss: 0.541..  Test Loss: 0.466..  Test Accuracy: 0.836\n",
      "Epoch: 2/2..  Training Loss: 0.553..  Test Loss: 0.447..  Test Accuracy: 0.835\n",
      "Epoch: 2/2..  Training Loss: 0.529..  Test Loss: 0.465..  Test Accuracy: 0.829\n",
      "Epoch: 2/2..  Training Loss: 0.491..  Test Loss: 0.455..  Test Accuracy: 0.832\n",
      "Epoch: 2/2..  Training Loss: 0.508..  Test Loss: 0.464..  Test Accuracy: 0.831\n",
      "Epoch: 2/2..  Training Loss: 0.525..  Test Loss: 0.448..  Test Accuracy: 0.835\n",
      "Epoch: 2/2..  Training Loss: 0.551..  Test Loss: 0.452..  Test Accuracy: 0.834\n",
      "Epoch: 2/2..  Training Loss: 0.465..  Test Loss: 0.462..  Test Accuracy: 0.832\n",
      "Epoch: 2/2..  Training Loss: 0.520..  Test Loss: 0.446..  Test Accuracy: 0.837\n",
      "Epoch: 2/2..  Training Loss: 0.549..  Test Loss: 0.445..  Test Accuracy: 0.839\n",
      "Epoch: 2/2..  Training Loss: 0.521..  Test Loss: 0.444..  Test Accuracy: 0.839\n"
     ]
    }
   ],
   "source": [
    "fc_model.train(model, trainloader, testloader, criterion, optimizer, epochs=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving and loading networks\n",
    "\n",
    "As you can imagine, it's impractical to train a network every time you need to use it. Instead, we can save trained networks then load them later to train more or use them for predictions.\n",
    "\n",
    "The parameters for PyTorch networks are stored in a model's `state_dict`. We can see the state dict contains the weight and bias matrices for each of our layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our model: \n",
      "\n",
      " Network(\n",
      "  (hidden_layers): ModuleList(\n",
      "    (0): Linear(in_features=784, out_features=512, bias=True)\n",
      "    (1): Linear(in_features=512, out_features=256, bias=True)\n",
      "    (2): Linear(in_features=256, out_features=128, bias=True)\n",
      "  )\n",
      "  (output): Linear(in_features=128, out_features=10, bias=True)\n",
      "  (dropout): Dropout(p=0.5)\n",
      ") \n",
      "\n",
      "The state dict keys: \n",
      "\n",
      " odict_keys(['hidden_layers.0.weight', 'hidden_layers.0.bias', 'hidden_layers.1.weight', 'hidden_layers.1.bias', 'hidden_layers.2.weight', 'hidden_layers.2.bias', 'output.weight', 'output.bias'])\n"
     ]
    }
   ],
   "source": [
    "print(\"Our model: \\n\\n\", model, '\\n')\n",
    "print(\"The state dict keys: \\n\\n\", model.state_dict().keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The simplest thing to do is simply save the state dict with `torch.save`. For example, we can save it to a file `'checkpoint.pth'`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'checkpoint.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we can load the state dict with `torch.load`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "odict_keys(['hidden_layers.0.weight', 'hidden_layers.0.bias', 'hidden_layers.1.weight', 'hidden_layers.1.bias', 'hidden_layers.2.weight', 'hidden_layers.2.bias', 'output.weight', 'output.bias'])\n"
     ]
    }
   ],
   "source": [
    "state_dict = torch.load('checkpoint.pth')\n",
    "print(state_dict.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And to load the state dict in to the network, you do `model.load_state_dict(state_dict)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_state_dict(state_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seems pretty straightforward, but as usual it's a bit more complicated. Loading the state dict works only if the model architecture is exactly the same as the checkpoint architecture. If I create a model with a different architecture, this fails."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Error(s) in loading state_dict for Network:\n\tWhile copying the parameter named \"hidden_layers.0.weight\", whose dimensions in the model are torch.Size([400, 784]) and whose dimensions in the checkpoint are torch.Size([512, 784]).\n\tWhile copying the parameter named \"hidden_layers.0.bias\", whose dimensions in the model are torch.Size([400]) and whose dimensions in the checkpoint are torch.Size([512]).\n\tWhile copying the parameter named \"hidden_layers.1.weight\", whose dimensions in the model are torch.Size([200, 400]) and whose dimensions in the checkpoint are torch.Size([256, 512]).\n\tWhile copying the parameter named \"hidden_layers.1.bias\", whose dimensions in the model are torch.Size([200]) and whose dimensions in the checkpoint are torch.Size([256]).\n\tWhile copying the parameter named \"hidden_layers.2.weight\", whose dimensions in the model are torch.Size([100, 200]) and whose dimensions in the checkpoint are torch.Size([128, 256]).\n\tWhile copying the parameter named \"hidden_layers.2.bias\", whose dimensions in the model are torch.Size([100]) and whose dimensions in the checkpoint are torch.Size([128]).\n\tWhile copying the parameter named \"output.weight\", whose dimensions in the model are torch.Size([10, 100]) and whose dimensions in the checkpoint are torch.Size([10, 128]).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-39-d859c59ebec0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfc_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNetwork\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m784\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m400\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m200\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# This will throw an error because the tensor sizes are wrong!\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mload_state_dict\u001b[0;34m(self, state_dict, strict)\u001b[0m\n\u001b[1;32m    719\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_msgs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    720\u001b[0m             raise RuntimeError('Error(s) in loading state_dict for {}:\\n\\t{}'.format(\n\u001b[0;32m--> 721\u001b[0;31m                                self.__class__.__name__, \"\\n\\t\".join(error_msgs)))\n\u001b[0m\u001b[1;32m    722\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    723\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Error(s) in loading state_dict for Network:\n\tWhile copying the parameter named \"hidden_layers.0.weight\", whose dimensions in the model are torch.Size([400, 784]) and whose dimensions in the checkpoint are torch.Size([512, 784]).\n\tWhile copying the parameter named \"hidden_layers.0.bias\", whose dimensions in the model are torch.Size([400]) and whose dimensions in the checkpoint are torch.Size([512]).\n\tWhile copying the parameter named \"hidden_layers.1.weight\", whose dimensions in the model are torch.Size([200, 400]) and whose dimensions in the checkpoint are torch.Size([256, 512]).\n\tWhile copying the parameter named \"hidden_layers.1.bias\", whose dimensions in the model are torch.Size([200]) and whose dimensions in the checkpoint are torch.Size([256]).\n\tWhile copying the parameter named \"hidden_layers.2.weight\", whose dimensions in the model are torch.Size([100, 200]) and whose dimensions in the checkpoint are torch.Size([128, 256]).\n\tWhile copying the parameter named \"hidden_layers.2.bias\", whose dimensions in the model are torch.Size([100]) and whose dimensions in the checkpoint are torch.Size([128]).\n\tWhile copying the parameter named \"output.weight\", whose dimensions in the model are torch.Size([10, 100]) and whose dimensions in the checkpoint are torch.Size([10, 128])."
     ]
    }
   ],
   "source": [
    "# Try this\n",
    "model = fc_model.Network(784, 10, [400, 200, 100])\n",
    "# This will throw an error because the tensor sizes are wrong!\n",
    "model.load_state_dict(state_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This means we need to rebuild the model exactly as it was when trained. Information about the model architecture needs to be saved in the checkpoint, along with the state dict. To do this, you build a dictionary with all the information you need to compeletely rebuild the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = {'input_size': 784,\n",
    "              'output_size': 10,\n",
    "              'hidden_layers': [each.out_features for each in model.hidden_layers],\n",
    "              'state_dict': model.state_dict()}\n",
    "\n",
    "torch.save(checkpoint, 'checkpoint.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the checkpoint has all the necessary information to rebuild the trained model. You can easily make that a function if you want. Similarly, we can write a function to load checkpoints. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_checkpoint(filepath):\n",
    "    checkpoint = torch.load(filepath)\n",
    "    model = fc_model.Network(checkpoint['input_size'],\n",
    "                             checkpoint['output_size'],\n",
    "                             checkpoint['hidden_layers'])\n",
    "    model.load_state_dict(checkpoint['state_dict'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Network(\n",
      "  (hidden_layers): ModuleList(\n",
      "    (0): Linear(in_features=784, out_features=400, bias=True)\n",
      "    (1): Linear(in_features=400, out_features=200, bias=True)\n",
      "    (2): Linear(in_features=200, out_features=100, bias=True)\n",
      "  )\n",
      "  (output): Linear(in_features=100, out_features=10, bias=True)\n",
      "  (dropout): Dropout(p=0.5)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = load_checkpoint('checkpoint.pth')\n",
    "print(model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
